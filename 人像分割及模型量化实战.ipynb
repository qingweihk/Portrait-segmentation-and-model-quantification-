{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人像分割及模型量化实战\n",
    "本项目基于PaddleSeg核心分割网络，提供针对人像分割场景从预训练模型、Fine-tune、视频分割预测部署。应用HumanSeg-lite模型超轻量级人像分割模型，支持移动端场景的实时分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 场景应用\n",
    "将人像与背景分离，可用于背景替换，如影视特效制作，全民小视频等APP中的人像分割并替换背景特效等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaddleSeg 安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  PaddleSeg.zip\r\n",
      "replace PaddleSeg/.pre-commit-config.yaml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "# 若在本地环境运行，使用git下载PaddleSeg代码\n",
    "#! git clone https://github.com/PaddlePaddle/PaddleSeg.git\n",
    "\n",
    "# 为快速，此处我们已下载PaddleSeg代码，解压后可直接执行后续代码\n",
    "!unzip PaddleSeg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进入人像分割目录\n",
    "%cd PaddleSeg/contrib/HumanSeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境依赖\n",
    "* Python == 3.5/3.6/3.7\n",
    "* PaddlePaddle >= 1.7.1\n",
    "通过以下命令安装python包依赖，确保至少执行过一次以下命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paddleslim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预训练模型\n",
    "HumanSeg开放了在大规模人像数据上训练的三个预训练模型，满足多种使用场景的需求\n",
    "| 模型类型 | Checkpoint | Inference Model | Quant Inference Model | 备注 |\n",
    "| --- | --- | --- | ---| --- |\n",
    "| HumanSeg-server  | [humanseg_server_ckpt](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_server_ckpt.zip) | [humanseg_server_inference](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_server_inference.zip) | -- | 高精度模型，适用于服务端GPU且背景复杂的人像场景， 模型结构为Deeplabv3+/Xcetion65, 输入大小（512， 512） |\n",
    "| HumanSeg-mobile | [humanseg_mobile_ckpt](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_mobile_ckpt.zip) | [humanseg_mobile_inference](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_mobile_inference.zip) | [humanseg_mobile_quant](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_mobile_quant.zip) | 轻量级模型, 适用于移动端或服务端CPU的前置摄像头场景，模型结构为HRNet_w18_samll_v1，输入大小（192， 192）  |\n",
    "| HumanSeg-lite | [humanseg_lite_ckpt](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_lite_ckpt.zip) | [humanseg_lite_inference](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_lite_inference.zip) |  [humanseg_lite_quant](https://paddleseg.bj.bcebos.com/humanseg/models/humanseg_lite_quant.zip) | 超轻量级模型, 适用于手机自拍人像，且有移动端实时分割场景， 模型结构为优化的ShuffleNetV2，输入大小（192， 192） |\n",
    "\n",
    "\n",
    "模型性能\n",
    "\n",
    "| 模型 | 模型大小 | 计算耗时 |\n",
    "| --- | --- | --- |\n",
    "|humanseg_server_inference| 158M | - |\n",
    "|humanseg_mobile_inference | 5.8 M | 42.35ms |\n",
    "|humanseg_mobile_quant | 1.6M | 24.93ms |\n",
    "|humanseg_lite_inference | 541K | 17.26ms |\n",
    "|humanseg_lite_quant | 187k | 11.89ms |\n",
    "\n",
    "计算耗时运行环境： 小米，cpu：骁龙855， 内存：6GB， 图片大小：192*192)\n",
    "\n",
    "**NOTE:**\n",
    "其中Checkpoint为模型权重，用于Fine-tuning场景。\n",
    "\n",
    "* Inference Model和Quant Inference Model为预测部署模型，包含`__model__`计算图结构、`__params__`模型参数和`model.yaml`基础的模型配置信息。\n",
    "\n",
    "* 其中Inference Model适用于服务端的CPU和GPU预测部署，Qunat Inference Model为量化版本，适用于通过Paddle Lite进行移动端等端侧设备部署。更多Paddle Lite部署说明查看[Paddle Lite文档](https://paddle-lite.readthedocs.io/zh/latest/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/download_data.py\n",
    "!python pretrained_weights/download_pretrained_weights.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载测试数据\n",
    "[supervise.ly](https://supervise.ly/)发布人像分割数据集**Supervisely Persons**, 从中随机抽取一小部分并转化成PaddleSeg可直接加载数据格式。通过运行以下代码进行快速下载，其中包含手机前置摄像头的人像测试视频`video_test.mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速体验视频流人像分割\n",
    "分割过程中，结合DIS（Dense Inverse Search-basedmethod）光流算法预测结果与分割结果，改善视频流人像分割。\n",
    "\n",
    "支持对摄像头获取的视频流进行实时分割，也支持对视频进行分割。在AIStudio运行仅支持对视频进行分割。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过电脑摄像头进行时分割处理\n",
    "# !python video_infer.py --model_dir pretrained_weights/humanseg_lite_inference\n",
    "\n",
    "#  对人像视频进行分割处理\n",
    "!python video_infer.py --model_dir pretrained_weights/humanseg_lite_inference --video_path data/video_test.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视频分割结果如下：\n",
    "\n",
    "<img src=\"https://paddleseg.bj.bcebos.com/humanseg/data/video_test.gif\" width=\"10%\" height=\"10%\"><img src=\"https://paddleseg.bj.bcebos.com/humanseg/data/result.gif\" width=\"10%\" height=\"10%\">\n",
    "\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "视频分割处理时间需要几分钟，请耐心等待。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "使用下述命令基于与训练模型进行Fine-tuning，请确保选用的模型结构`model_type`与模型参数`pretrained_weights`匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --model_type HumanSegMobile \\\n",
    "--save_dir output/ \\\n",
    "--data_dir data/mini_supervisely \\\n",
    "--train_list data/mini_supervisely/train.txt \\\n",
    "--val_list data/mini_supervisely/val.txt \\\n",
    "--pretrained_weights pretrained_weights/humanseg_mobile_ckpt \\\n",
    "--batch_size 8 \\\n",
    "--learning_rate 0.001 \\\n",
    "--num_epochs 10 \\\n",
    "--image_shape 192 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_type`: 模型类型，可选项为：HumanSegServer、HumanSegMobile和HumanSegLite\n",
    "* `--save_dir`: 模型保存路径\n",
    "* `--data_dir`: 数据集路径\n",
    "* `--train_list`: 训练集列表路径\n",
    "* `--val_list`: 验证集列表路径\n",
    "* `--pretrained_weights`: 预训练模型路径\n",
    "* `--batch_size`: 批大小\n",
    "* `--learning_rate`: 初始学习率\n",
    "* `--num_epochs`: 训练轮数\n",
    "* `--image_shape`: 网络输入图像大小（w, h）\n",
    "\n",
    "更多命令行帮助可运行下述命令进行查看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "可通过更换`--model_type`变量与对应的`--pretrained_weights`使用不同的模型快速尝试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估\n",
    "使用下述命令进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py --model_dir output/best_model \\\n",
    "--data_dir data/mini_supervisely \\\n",
    "--val_list data/mini_supervisely/val.txt \\\n",
    "--image_shape 192 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_dir`: 模型路径\n",
    "* `--data_dir`: 数据集路径\n",
    "* `--val_list`: 验证集列表路径\n",
    "* `--image_shape`: 网络输入图像大小（w, h）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测\n",
    "使用下述命令进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python infer.py --model_dir output/best_model \\\n",
    "--data_dir data/mini_supervisely \\\n",
    "--test_list data/mini_supervisely/test.txt \\\n",
    "--image_shape 192 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_dir`: 模型路径\n",
    "* `--data_dir`: 数据集路径\n",
    "* `--test_list`: 测试集列表路径\n",
    "* `--image_shape`: 网络输入图像大小（w, h）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果展示\n",
    "图片预测结果默认保存在output/result目录中， 分别保存有叠加图、scoremap和人像扣取结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# 定义显示函数\n",
    "def display(img_dir, title, flag=0):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(title)):\n",
    "        if flag:\n",
    "            plt.subplot(len(img_dir), 1, i+1)\n",
    "        else:\n",
    "            plt.subplot(1, len(img_dir), i+1)\n",
    "        plt.title(title[i])\n",
    "        img = plt.imread(img_dir[i])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果展示\n",
    "added_path = \"output/result/added/Images/pexels-photo-573300_KrLVVmXzru.png\"\n",
    "score_path = \"output/result/scoremap/Images/pexels-photo-573300_KrLVVmXzru.png\"\n",
    "mat_path = \"output/result/mat/Images/pexels-photo-573300_KrLVVmXzru.png\"\n",
    "display([added_path, score_path, mat_path], ['added Image', 'scoremap', 'mat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python export.py --model_dir output/best_model \\\n",
    "--save_dir output/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_dir`: 模型路径\n",
    "* `--save_dir`: 导出模型保存路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 离线量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python quant_offline.py --model_dir output/best_model \\\n",
    "--data_dir data/mini_supervisely \\\n",
    "--quant_list data/mini_supervisely/val.txt \\\n",
    "--save_dir output/quant_offline \\\n",
    "--image_shape 192 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_dir`: 待量化模型路径\n",
    "* `--data_dir`: 数据集路径\n",
    "* `--quant_list`: 量化数据集列表路径，一般直接选择训练集或验证集\n",
    "* `--save_dir`: 量化模型保存路径\n",
    "* `--image_shape`: 网络输入图像大小（w, h）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在线量化\n",
    "利用float训练模型进行在线量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python quant_online.py --model_type HumanSegMobile \\\n",
    "--save_dir output/quant_online \\\n",
    "--data_dir data/mini_supervisely \\\n",
    "--train_list data/mini_supervisely/train.txt \\\n",
    "--val_list data/mini_supervisely/val.txt \\\n",
    "--pretrained_weights output/best_model \\\n",
    "--batch_size 2 \\\n",
    "--learning_rate 0.001 \\\n",
    "--num_epochs 2 \\\n",
    "--image_shape 192 192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数含义如下：\n",
    "* `--model_type`: 模型类型，可选项为：HumanSegServer、HumanSegMobile和HumanSegLite\n",
    "* `--save_dir`: 模型保存路径\n",
    "* `--data_dir`: 数据集路径\n",
    "* `--train_list`: 训练集列表路径\n",
    "* `--val_list`: 验证集列表路径\n",
    "* `--pretrained_weights`: 预训练模型路径,\n",
    "* `--batch_size`: 批大小\n",
    "* `--learning_rate`: 初始学习率\n",
    "* `--num_epochs`: 训练轮数\n",
    "* `--image_shape`: 网络输入图像大小（w, h）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "在线量化的效果不一定优于离线量化。离线量化操作简单，对于量化不甚了解的同学推荐直接使用离线量化即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
